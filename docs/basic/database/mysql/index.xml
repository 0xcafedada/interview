<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Interview</title>
    <link>https://hadyang.github.io/interview/docs/basic/database/mysql/</link>
    <description>Recent content on Interview</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Wed, 19 Feb 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://hadyang.github.io/interview/docs/basic/database/mysql/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>分库分表</title>
      <link>https://hadyang.github.io/interview/docs/basic/database/mysql/sharding/</link>
      <pubDate>Wed, 19 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://hadyang.github.io/interview/docs/basic/database/mysql/sharding/</guid>
      <description>分库分表 目前绝大多数应用采取的两种分库分表规则
 mod方式 dayofweek系列日期方式（所有星期1的数据在一个库/表,或所有?月份的数据在一个库表）  这两种方式有个本质的特点，就是 离散性加周期性。例如以一个表的主键对 3 取余数的方式分库或分表：
那么随着数据量的增大，每个表或库的数据量都是各自增长。当一个表或库的数据量增长到了一个极限，要加库或加表的时候， 介于这种分库分表算法的离散性，必需要做数据迁移才能完成。例如从3个扩展到5个的时候：
需要将原先以 mod3 分类的数据，重新以 mod5 分类，不可避免的带来数据迁移。每个表的数据都要被重新分配到多个新的表 相似的例子比如从 dayofweek 分的 7 个库/表,要扩张为以 dayofmonth 分的 31 张库/表，同样需要进行数据迁移。
数据迁移带来的问题是
 业务至少要两次发布 要专门写工具来导数据。由于各业务之间的差别，很难做出统一的工具。目前几乎都是每个业务写一套 要解决增量、全量、时间点，数据不一致等问题  如何在数据量扩张到现有库表极限，加库加表时避免数据迁移呢？
通常的数据增长往往是随着时间的推移增长的。随着业务的开展，时间的推移，数据量不断增加。
考虑到数据增长的特点，如果我们以代表时间增长的字段，按递增的范围分库，则可以避免数据迁移。这样的方式下，在数据量再增加达到前几个库/表的上限时，则继续水平增加库表，原先的数据就不需要迁移了。但是这样的方式会带来一个 热点问题：当前的数据量达到某个库表的范围时，所有的插入操作，都集中在这个库/表了。
所以在满足基本业务功能的前提下，分库分表方案应该尽量避免的两个问题：
 数据迁移 热点  如何既能避免数据迁移又能避免插入更新的热点问题呢？
结合离散分库/分表和连续分库/分表的优点，如果一定要写热点和新数据均匀分配在每个库，同时又保证易于水平扩展，可以考虑这样的模式：
水平扩展scale-out方案 &amp;ndash; 模式一 阶段一 一个库 DB0 之内分4个表，id%4 ：
阶段二 增加 DB1 库，t2和t3整表搬迁到 DB1
阶段三 增加 DB2 和 DB3 库，t1 整表搬迁到 DB2 ，t3整表搬迁的 DB3：
为了规则表达，通过内部名称映射或其他方式，我们将DB1和DB2的名称和位置互换得到下图：
dbRule: “DB” + (id % 4) tbRule: “t” + (id % 4) 即逻辑上始终保持4库4表，每个表一个库。这种做法也是目前店铺线图片空间采用的做法。</description>
    </item>
    
    <item>
      <title>MySQL 架构</title>
      <link>https://hadyang.github.io/interview/docs/basic/database/mysql/architecture/</link>
      <pubDate>Tue, 18 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://hadyang.github.io/interview/docs/basic/database/mysql/architecture/</guid>
      <description>MySQL 架构 总体来说 MySQL 可以分为两层，第一层是 MySQL 的服务层，包含 MySQL 核心服务功能：解析、分析、优化、缓存以及内置函数，所有跨存储引擎的功能都在这一层实现：存储过程、触发器、视图等。
第二层是 MySQL 的 存储引擎层，MySQL 中可使用多种存储引擎：InnoDB、MyISAM、Memory。存储引擎负责 MySQL 中数据的存取。服务层通过统一的 API 与存储引擎进行通信，这些 API 屏蔽来同步存储引擎之间的差异，使得这些差异对上层的查询过程透明。
MySQL Server 连接器 连接器负责跟客户端建立连接、获取权限、维持和管理连接。
查询缓存 查询缓存将查询结果按 K-V 的形式进行缓存，K 是查询的语句，V 是查询的结果。当一个表发生更新后，该表对应的所有缓存均会失效。
分析器 分析器有两个功能：词法分析、语法分析。对于一个 SQL 语句，分析器首先进行词法分析，对 SQL 语句进行拆分，识别出各个字符串代表的含义。然后就是语法分析，分析器根据定义的语法规则判断 SQL 是否满足 MySQL 语法。
优化器 优化器在获取到分析器的结果后，通过表结构和 SQL 语句选择执行方案，比如：多表关联时，各个表如何进行连接；当表中有索引时，应该怎样选择索引 等等。
执行器 获取到执行方案后，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。在进行查询时，MySQL 执行器内部执行步骤如下：
 调用引擎接口取这个表的第一行，判断该行是否满足 WHERE 子句，如果满足则将这行存在结果集中，否则跳过。 调用引擎接口取下一行，重复相同的判断逻辑，直到取到这个表的最后一行。 执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。  对于走索引的查询，执行的逻辑也差不多。第一次调用的是 取满足条件的第一行 这个接口，之后循环取 满足条件的下一行 这个接口，这些接口都是引擎中已经定义好的。
Update 处理逻辑 这里简单的分析下 Update 的处理逻辑
 MySQL Server 发送更新请求到 InnoDB 引擎 从 Buffer Pool 加载对应记录的 Data Page（P1）  若 Buffer Pool 中没有该记录，则从磁盘加载该记录   将 P1 存储到 Undo Page 中，并在 Redo Log Buffer 中记录 Undo 操作 更新 P1 为 P1&amp;rsquo; ，并将 P1&amp;rsquo; 写入 Dirty Page ，记录变更到 Redo Log Buffer（Prepare 状态） 返回 MySQL Server 执行完成 MySQL Server 记录 binlog MySQL Server 提交 Commit Redo Log Buffer 状态有 Prepare 更改为 Commit，并刷入磁盘 当 Dirty Page 过多时，启动 ChcekPoint 机制，将脏页刷入磁盘  </description>
    </item>
    
  </channel>
</rss>