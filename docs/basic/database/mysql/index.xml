<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Interview</title>
    <link>https://hadyang.github.io/interview/docs/basic/database/mysql/</link>
    <description>Recent content on Interview</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Wed, 19 Feb 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://hadyang.github.io/interview/docs/basic/database/mysql/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>MySQL 集群</title>
      <link>https://hadyang.github.io/interview/docs/basic/database/mysql/sharding/</link>
      <pubDate>Wed, 19 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://hadyang.github.io/interview/docs/basic/database/mysql/sharding/</guid>
      <description>分库分表 垂直拆分 垂直分表 也就是 大表拆小表，基于列字段进行的。一般是表中的字段较多，将不常用的， 数据较大，长度较长（比如text类型字段）的拆分到 扩展表。 一般是针对那种几百列的大表，也避免查询时，数据量太大造成的 off-page 问题。
垂直分库 针对的是一个系统中的不同业务进行拆分。将多个业务系统的数据放在单个数据库中（服务化拆分），这会让数据库的单库处理能力成为瓶颈。将单个数据库，按业务进行拆分，同一业务领域的数据表放到同一数据库中。并且多个数据库分布在多个机器上，防止由于单机的磁盘、内存、IO等资源造成 MySQL 性能下降。
数据库的连接资源比较宝贵且单机处理能力也有限，在高并发场景下，垂直分库一定程度上能够突破 IO、连接数等单机硬件资源的瓶颈。
水平拆分 目前绝大多数应用采取的两种分库分表规则
 离散映射：如 mod 或 dayofweek ， 这种类型的映射能够很好的解决热点问题，但带来了数据迁移和历史数据问题。 连续映射；如按 id 或 gmt_create_time 的连续范围做映射。这种类型的映射可以避免数据迁移，但又带来热点问题。  随着数据量的增大，每个表或库的数据量都是各自增长。当一个表或库的数据量增长到了一个极限，要加库或加表的时候，介于这种分库分表算法的离散性，必需要做 数据迁移 才能完成。
考虑到数据增长的特点，如果我们以代表时间增长的字段，按递增的范围分库，则可以避免数据迁移。这样的方式下，在数据量再增加达到前几个库/表的上限时，则继续水平增加库表，原先的数据就不需要迁移了。但是这样的方式会带来一个 热点问题：当前的数据量达到某个库表的范围时，所有的插入操作，都集中在这个库/表了。
结合离散分库/分表和连续分库/分表的优点，可使要热点和新数据均匀分配在每个库，同时又保证易于水平扩展。分库分表的主要经历以下三个阶段：
阶段一 一个数据库，两个表，rule0 = id % 2
分库规则dbRule: “DB0″ 分表规则tbRule: “t” + (id % 2) 阶段二 当单库的数据量接近 1千万，单表的数据量接近 500 万时，进行扩容（数据量只是举例，具体扩容量要根据数据库和实际压力状况决定）：增加一个数据库 DB1，将 DB0.t0 整表迁移到新库 DB1.t1。每个库各增加1个表，未来10M-20M的数据mod2分别写入这2个表：t0_1，t1_1：
分库规则dbRule:
“DB” + (id % 2) 分表规则tbRule:
 if(id &amp;lt; 1千万){ return &amp;quot;t&amp;quot;+ (id % 2); //1千万之前的数据，仍然放在t0和t1表。t1表从DB0搬迁到DB1库 }else if(id &amp;lt; 2千万){ return &amp;quot;t&amp;quot;+ (id % 2) +&amp;quot;_1&amp;quot;; //1千万之后的数据，各放到两个库的两个表中: t0_1,t1_1 }else{ throw new IllegalArgumentException(&amp;quot;id outof range[20000000]:&amp;quot; + id); } 这样 10M 以后的新生数据会均匀分布在 DB0 和 DB1; 插入更新和查询热点仍然能够在每个库中均匀分布。每个库中同时有老数据和不断增长的新数据。每表的数据仍然控制在 500万 以下。</description>
    </item>
    
    <item>
      <title>MySQL 架构</title>
      <link>https://hadyang.github.io/interview/docs/basic/database/mysql/architecture/</link>
      <pubDate>Tue, 18 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://hadyang.github.io/interview/docs/basic/database/mysql/architecture/</guid>
      <description>MySQL 架构 总体来说 MySQL 可以分为两层，第一层是 MySQL 的服务层，包含 MySQL 核心服务功能：解析、分析、优化、缓存以及内置函数，所有跨存储引擎的功能都在这一层实现：存储过程、触发器、视图等。
第二层是 MySQL 的 存储引擎层，MySQL 中可使用多种存储引擎：InnoDB、MyISAM、Memory。存储引擎负责 MySQL 中数据的存取。服务层通过统一的 API 与存储引擎进行通信，这些 API 屏蔽来同步存储引擎之间的差异，使得这些差异对上层的查询过程透明。
MySQL Server 连接器 连接器负责跟客户端建立连接、获取权限、维持和管理连接。
查询缓存 查询缓存将查询结果按 K-V 的形式进行缓存，K 是查询的语句，V 是查询的结果。当一个表发生更新后，该表对应的所有缓存均会失效。
分析器 分析器有两个功能：词法分析、语法分析。对于一个 SQL 语句，分析器首先进行词法分析，对 SQL 语句进行拆分，识别出各个字符串代表的含义。然后就是语法分析，分析器根据定义的语法规则判断 SQL 是否满足 MySQL 语法。
优化器 优化器在获取到分析器的结果后，通过表结构和 SQL 语句选择执行方案，比如：多表关联时，各个表如何进行连接；当表中有索引时，应该怎样选择索引 等等。
执行器 获取到执行方案后，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。在进行查询时，MySQL 执行器内部执行步骤如下：
 调用引擎接口取这个表的第一行，判断该行是否满足 WHERE 子句，如果满足则将这行存在结果集中，否则跳过。 调用引擎接口取下一行，重复相同的判断逻辑，直到取到这个表的最后一行。 执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。  对于走索引的查询，执行的逻辑也差不多。第一次调用的是 取满足条件的第一行 这个接口，之后循环取 满足条件的下一行 这个接口，这些接口都是引擎中已经定义好的。
Update 处理逻辑 这里简单的分析下 Update 的处理逻辑
 MySQL Server 发送更新请求到 InnoDB 引擎 从 Buffer Pool 加载对应记录的 Data Page（P1）  若 Buffer Pool 中没有该记录，则从磁盘加载该记录   将 P1 存储到 Undo Page 中，并在 Redo Log Buffer 中记录 Undo 操作 更新 P1 为 P1&amp;rsquo; ，并将 P1&amp;rsquo; 写入 Dirty Page ，记录变更到 Redo Log Buffer（Prepare 状态） 返回 MySQL Server 执行完成 MySQL Server 记录 binlog MySQL Server 提交 Commit Redo Log Buffer 状态有 Prepare 更改为 Commit，并刷入磁盘 当 Dirty Page 过多时，启动 ChcekPoint 机制，将脏页刷入磁盘  </description>
    </item>
    
  </channel>
</rss>